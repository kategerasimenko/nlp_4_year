{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from pymystem3 import Mystem\n",
    "from string import punctuation\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import json\n",
    "from gensim.models.fasttext import FastText\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Данные\n",
    "**коса** - прическа и рельеф.\n",
    "\n",
    "### рельеф\n",
    "\n",
    "* Основной и газетный корпуса НКРЯ\n",
    "* Несколько контекстов\n",
    "  * песчаный|залив|отлог|вода|море в контексте от -15 до +15\n",
    "  * *на* перед *коса*\n",
    "* Удалить примеры с «Тузла», «Куршская»\n",
    "* чистка мусора\n",
    "\n",
    "### прическа\n",
    "\n",
    "* Основной корпус НКРЯ\n",
    "* заплести|расплести|сплести|плести|распустить|волосы|девушка|женщина|девочка|голова|отрезать в контексте от -15 до +15\n",
    "* удалить все примеры с «пробор» (там были нормальные, но у нас и без них много примеров)\n",
    "\n",
    "еще удалить дубликаты из примеров.\n",
    "\n",
    "Итого:\n",
    "* 571 коса-рельеф (0)\n",
    "* 589 коса-прическа (1)\n",
    "\n",
    "Всего - 1160 примеров. <br>\n",
    "Вообще, кажется, ситуация довольно искусственная, потому что самыми важными признаками для классификатора скорее всего станут те контекстные слова, по которым я вытаскивала примеры. Но мне все же кажется, что более-менее это отражает некоторую реальность, хотя честная ручная разметка всех примеров подряд была бы лучше, а в реальных проектах уж точно. Зато можно порадоваться высокому качеству (spoiler) хоть где-то :)\n",
    "\n",
    "# Препроцессинг\n",
    "\n",
    "* токенизатор+лемматизатор – mystem. Проблема pymorphy2 – лемматизирует «косу» как «кос», а «косы» как «коса».\n",
    "* Стоп-слова - из NLTK минус \"на\" (важный признак для косы-рельефа) и плюс \"коса\", чтобы удобно ее выкинуть и учитывать только контекст. Стоп-слова выкидываю на стадии векторизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('russian')) - set(['на'])\n",
    "stop.add('коса')\n",
    "m = Mystem(entire_input=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(filename):\n",
    "    full_examples = []\n",
    "    data = []\n",
    "    target = []\n",
    "    with open(filename,'r',encoding='utf-8') as f:\n",
    "        for line in tqdm(f.readlines()):\n",
    "            t,d = line.strip().split('\\t')\n",
    "            full_examples.append(d.strip())\n",
    "            d_lemmas = m.lemmatize(d)\n",
    "            data.append(' '.join(d_lemmas))\n",
    "            target.append(int(t))\n",
    "    return full_examples,data,target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1160/1160 [19:19<00:00,  1.00it/s]\n"
     ]
    }
   ],
   "source": [
    "full_examples,data,target = get_data('examples.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# записать лемматизацию (mystem немного долгий) и остальное заодно, чтобы не парсить сырой файл потом\n",
    "with open('examples_lemmatized.json','w',encoding='utf-8') as f:\n",
    "    s = (json.dumps({'full_examples':full_examples,'data':data,'target':target},ensure_ascii=False))\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# открыть лемматизацию\n",
    "with open('examples_lemmatized.json','r',encoding='utf-8') as f:\n",
    "    d = json.load(f)\n",
    "data = d['data']\n",
    "target = d['target']\n",
    "full_examples = d['full_examples']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Векторизация\n",
    "* TfidfVectorizer\n",
    "* Средние векторов из дистрибутивной семантики (FastText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words=stop)\n",
    "data_tfidf = tfidf.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distrib_vect(sentence):\n",
    "    tokens = sentence.split(' ')\n",
    "    vects = []\n",
    "    for token in tokens: # add pmi weight?\n",
    "        if token not in stop and token in distrib:\n",
    "            vects.append(distrib[token])\n",
    "    return np.average(np.array(vects),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "distrib = FastText.load('m/araneum_none_fasttextskipgram_300_5_2018.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Андрей\\Anaconda3\\envs\\python36\\lib\\site-packages\\ipykernel\\__main__.py:5: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "C:\\Users\\Андрей\\Anaconda3\\envs\\python36\\lib\\site-packages\\ipykernel\\__main__.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    }
   ],
   "source": [
    "data_distrib = [distrib_vect(x) for x in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Классификация\n",
    "На дефолтных параметрах:\n",
    "* Logistic Regression\n",
    "* Gradient Boosting Classifier\n",
    "* Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_preds(data,target,clf):\n",
    "    y_pred = cross_val_predict(clf,data,target,cv=5)\n",
    "    print(f1_score(target,y_pred))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    'TfidfVectorizer': data_tfidf,\n",
    "    'FastText': data_distrib\n",
    "}\n",
    "\n",
    "clfs = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42),\n",
    "    'Gradient Boosting Classifier': GradientBoostingClassifier(random_state=42),\n",
    "    'Random Forest Classifier': RandomForestClassifier(random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression & TfidfVectorizer\n",
      "0.9881355932203391\n",
      "Logistic Regression & FastText\n",
      "0.9727891156462585\n",
      "\n",
      "Gradient Boosting Classifier & TfidfVectorizer\n",
      "0.9837745516652434\n",
      "Gradient Boosting Classifier & FastText\n",
      "0.9677966101694915\n",
      "\n",
      "Random Forest Classifier & TfidfVectorizer\n",
      "0.9522983521248916\n",
      "Random Forest Classifier & FastText\n",
      "0.9343696027633851\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for clf_label,clf in clfs.items():\n",
    "    for d_label,d in data_dict.items():\n",
    "        print(clf_label,'&',d_label)\n",
    "        _ = get_preds(d,target,clf)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самая лучшая комбинация - Logistic Regression & TfidfVectorizer. FastText везде сработал хуже. Возможно, к нему лучше добавить веса PMI слов из контекста и рассматриваемого слова.<br>\n",
    "Дальше будем рассматривать только Logistic Regression & TfidfVectorizer.\n",
    "\n",
    "# Ошибки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9881355932203391\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=42)\n",
    "y_pred = get_preds(data_tfidf,target,clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 14 errors\n",
      "true pred sentence\n",
      "0 1 ― Гээнта спит где-нибудь на косе, ― сказал свое Кялундзига.\n",
      "0 1 Ксюта подняла голову из воды и увидела на галечной косе рядом со своей одеждой чернобородого человека недеревенской наружности в клетчатой ковбойке с закатанными рукавами, отмахивавшегося геологическим молотком от разъяренно прыгающего вокруг него Чарли.\n",
      "0 1 Наталка шептала без умолку обо всем, что ей приходило в голову, ― обо всех новостях на косе, о том, например, что, говорят, в степи ходит по шляхам старуха с железными глазами и на кого ни глянет ― у того непременно убьют кого-нибудь на войне.\n",
      "0 1 Белые медведи знают это и в голодные весенние месяцы выходят на косу.\n",
      "0 1 Он поднял вдоль статуи голову и увидел, что Царь ни черта не видит в той стороне, в которую плыла девочка: ни Волги, ни Бирючьей косы, ни моря, ни персидских сладких, как клубника, лимонов, ни жарких берегов, где девочка могла бы хорошенько погреться…\n",
      "0 1 Она приняла руку, хотя чувствовала себя вполне уверенно.   Искупались и решили взглянуть на косу.  Шофёр ждал наверху.\n",
      "0 1 Так просто посидеть с удочкой, поразмышлять.   ― На косе собирали грибы?   ― Белые.\n",
      "0 1 Так, уже за цветным эпилогом «Рублева», за аккордом нежных красок снова возникает «опознавательный» кадр пасущихся на косе коней.\n",
      "1 0 Здесь нашла коса на камень: прорыв 34-й армии наткнулся на встречный удар дивизии СС \"Мёртвая голова\", и 40-километровый Рамушевский коридор тридцать четвёртой перерезать не удалось.\n",
      "1 0 А вот про встречу в тубдиспансере я умолчал, зато рассказал о том, как шли мы, опять же с поклажей картошки, из Архиповки и видели, как нелепо и страшно тонули на реке Чусовой пьяные люди, пробовавшие плясать в лодке и опрокинувшие ее, как в холодные воды бросился человек ― спасать людей ― и спас молодую девушку с длинной косой, это был, показалось нам, Радыгин.\n",
      "1 0 Сначала Галя заплетала девочке косу, поварчивая на Сеню, как река поварчивает на берег, катая волны.\n",
      "1 0 Женщина со странностями: в семьдесят лет она вплетала в косы бантики, уверяя, что похожа как две капли воды на Рину Зеленую.\n",
      "1 0 Солнышко слезло с оленя и, распустив огненные косы, вместе с оленем стало купаться в переливающейся «живой воде».\n",
      "1 0 Бывали дни, когда она не могла приблизиться к морскому берегу: огромные волны бились о скалы, накатывались на галечную косу, кидаясь на одинокую девушку, стоявшую на высокой галечной гряде.\n"
     ]
    }
   ],
   "source": [
    "error_idx = np.where(y_pred != np.array(target))\n",
    "print('Total',len(error_idx[0]),'errors')\n",
    "print('true','pred','sentence')\n",
    "for e in error_idx[0]:\n",
    "    print(target[e],y_pred[e],full_examples[e])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Всего 14 ошибок на всем корпусе.\n",
    "\n",
    "Во многих случаях, где в действительности коса-рельеф, а классификатор считает, что это коса-прическа, это \"на косе\" и отсутствие других ключевых для косы-рельефа слов.\n",
    "\n",
    "Там, где ошибка в сторону косы-рельефа для контекстов косы-прически, фигурируют ключевые слова для косы-рельефа (вода, волны), причем первая ошибка - это мусор, коса-инструмент, и последняя - тоже неверный класс в разметке (из-за слова \"девушка\").\n",
    "\n",
    "Возможно, что такая зависимость от ключевых слов лечится честной разметкой :)\n",
    "\n",
    "# Уменьшение размерности\n",
    "PCA - до 5 измерений (уменьшить примерно в 1000 раз).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9796954314720812\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components = 5, random_state = 42)\n",
    "data_tfidf_pca = pca.fit_transform(data_tfidf.todense())\n",
    "_ = get_preds(data_tfidf_pca,target,clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество ухудшилось, но ненамного для такого уменьшения размерности.\n",
    "# Другие примеры\n",
    "Взяты из Araneum Russicum Minus по запросу \"коса\" (без контекстных слов)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [00:09<00:00,  1.01it/s]\n"
     ]
    }
   ],
   "source": [
    "test_examples,test_data,test_target = get_data('test_examples.txt')\n",
    "test_tfidf_data = tfidf.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true pred sentence\n",
      "1 1 Для женщины однако, во все времена и страны, длинные косы считались украшением.\n",
      "1 1 Невеста заплетала шесть кос и, перевязав их красной лентой, укладывала вокруг головы.\n",
      "1 1 А XIX век подарил дамам прическу «бараний рог»: косы плели не с самого начала локона, а с средины.\n",
      "1 1 Мама сегодня в цветастом крепдешиновом платье, ее большая, золотистая коса уложена венком по тогдашней моде, но особенно красив отец в летной фуражке, зеленой гимнастерке с полыхающими на солнце погонами!\n",
      "1 1 Вынуждена была отрезать косу , потому, что одной рукой не могла ее расчёсывать.\n",
      "0 0 Самой интересной особенностью Азовского моря является наличие на его побережье большого количества кос.\n",
      "0 0 Но упёрлись в песчаную косу, далёко уходящую в море.\n",
      "0 0 Генеральным планом развития Евпатории определено новое место под порт – район Южной косы озера Донузлав, где расположен грузовой район по добыче и транспортировке песка.\n",
      "0 0 Почти прямо напротив площадки (чуть правее) в море выдавалась своеобразная коса, закрывающая от моря буквой С примерно пятидесятиметровый заливчик, изнутри заботливо усыпанный мелким песочком, а снаружи укрепленный полутонными бетонными блоками.\n",
      "0 0 После одного сильного шторма реку перегородило косой, и вода ринулась в новое русло — как раз по карьерным разработкам.\n"
     ]
    }
   ],
   "source": [
    "clf.fit(data_tfidf,target) # обучаем на всем\n",
    "y_pred = clf.predict(test_tfidf_data)\n",
    "\n",
    "print('true','pred','sentence')\n",
    "for i,pred in enumerate(y_pred):\n",
    "    print(test_target[i],pred,test_examples[i]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все предсказания верны."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python36]",
   "language": "python",
   "name": "conda-env-python36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
