{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from pymystem3 import Mystem\n",
    "from collections import defaultdict, Counter\n",
    "from itertools import combinations\n",
    "import json\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = Mystem(entire_input=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('seed.txt','r',encoding='utf-8') as f:\n",
    "    gs = [x.strip() for x in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lemmatized (mystem) texts\n",
    "with open('lemmas.txt','r',encoding='utf-8') as f:\n",
    "    lemmas = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19034\n",
      "3022287\n"
     ]
    }
   ],
   "source": [
    "print(len(lemmas))\n",
    "print(sum([len(x) for x in lemmas]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Word2Vec(lemmas, size=300, window=7, min_count=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# find most similar - 2 levels\n",
    "\n",
    "def w2v_crawl_shrinked(word):\n",
    "    all_words = set()\n",
    "    lemma = m.lemmatize(word)\n",
    "    if len(lemma) == 1:\n",
    "        lemma = lemma[0]\n",
    "        if lemma in model:\n",
    "            sim1 = {x[0] for x in model.wv.most_similar(lemma) if model.similarity(lemma,x[0]) >= 0.6}\n",
    "            all_words |= sim1\n",
    "            for w in sim1:\n",
    "                sim2 = {x[0] for x in model.wv.most_similar(w) if model.similarity(lemma,x[0]) >= 0.6}\n",
    "                all_words |= sim2\n",
    "    return all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "аналогов нет 0\n",
      "подошва 72\n",
      "вежливый 15\n",
      "великолепный 24\n",
      "вкусный 6\n",
      "внимательный 19\n",
      "большой выбор 0\n",
      "вау 79\n",
      "неплохой 15\n",
      "идеальный 11\n",
      "неприятный 0\n",
      "понравилось 6\n",
      "рекомендуем 2\n",
      "на ура 0\n",
      "советуем 2\n",
      "отвратительный 12\n",
      "отличный 20\n",
      "положительный 13\n",
      "отрицательный 21\n",
      "приятный 11\n",
      "напоминать о себе 0\n",
      "спасибо 13\n",
      "радовать глаз 0\n",
      "на совесть 0\n",
      "молодцы 38\n",
      "придти еще раз 0\n",
      "орать 46\n",
      "улыбаться 39\n",
      "приветливый 16\n",
      "отличный 20\n",
      "замечательный 21\n"
     ]
    }
   ],
   "source": [
    "all_words = set()\n",
    "for word in gs:\n",
    "    curr_words = w2v_crawl_shrinked(word)\n",
    "    print(word,len(curr_words))\n",
    "    all_words |= curr_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=stopwords.words('russian'), min_df = 10)\n",
    "A = vectorizer.fit_transform([' '.join(x) for x in lemmas])\n",
    "terms = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# show topic descriptors\n",
    "def get_descriptor( terms, H, topic_index, top ):\n",
    "    top_indices = np.argsort( H[topic_index,:] )[::-1]\n",
    "    top_terms = []\n",
    "    for term_index in top_indices[0:top]:\n",
    "        top_terms.append( terms[term_index] )\n",
    "    return top_terms\n",
    "\n",
    "def get_all_descriptors(k, H, terms, top):\n",
    "    for topic_index in range(k):\n",
    "        descriptor = get_descriptor( terms, H, topic_index, top )\n",
    "        str_descriptor = \", \".join( descriptor )\n",
    "        print(\"Topic %02d: %s\" % ( topic_index+1, str_descriptor ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 01: салат, соус, суп, блюдо, вкус, мясо, десерт, меню, овощ, тарелка\n",
      "Topic 02: quot, вопрос, название, цезарь, слово, сегодня, ответ, официантка, который, спрашивать\n",
      "Topic 03: понравиться, очень, особенно, обязательно, прийти, еда, интерьер, зайти, друг, подруга\n",
      "Topic 04: свадьба, спасибо, гость, наш, весь, банкет, праздник, зал, огромный, оставаться\n",
      "Topic 05: это, мочь, место, весь, сказать, который, человек, свой, стол, зал\n",
      "Topic 06: приносить, минута, заказ, ждать, официант, заказывать, столик, официантка, счет, час\n",
      "Topic 07: ресторан, блюдо, посещать, любимый, ваш, отзыв, год, повар, это, официант\n",
      "Topic 08: пиво, паб, пивной, сорт, закуска, бар, попить, футбол, гренок, колбаска\n",
      "Topic 09: отличный, место, рекомендовать, советовать, сервис, кухня, друг, замечательный, уютно, отдых\n",
      "Topic 10: очень, вкусно, уютно, быстро, вкусный, довольный, приятно, оставаться, красиво, большой\n",
      "Topic 11: кухня, обслуживание, интерьер, уровень, высокий, неплохой, официант, замечательный, мочь, сервис\n",
      "Topic 12: приятный, атмосфера, уютный, музыка, вкусный, персонал, обстановка, вечер, место, еда\n",
      "Topic 13: день, рождение, отмечать, друг, компания, свой, ребенок, праздник, детский, праздновать\n",
      "Topic 14: заведение, данный, посещать, персонал, ваш, клиент, посещение, работа, свой, подобный\n",
      "Topic 15: пицца, паста, вкусный, заказывать, тесто, итальянский, доставка, пиццерия, ребенок, сыр\n",
      "Topic 16: цена, кафе, качество, порция, блюдо, еда, ланч, бизнес, большой, меню\n",
      "Topic 17: суша, ролл, японский, вкусный, бар, угорь, рис, филадельфия, лосось, запекать\n",
      "Topic 18: хороший, самый, город, место, сервис, желать, оставлять, впечатление, бывать, рекомендовать\n",
      "Topic 19: супер, просто, класс, весь, спасибо, молодец, советовать, замечательный, прийти, держать\n",
      "Topic 20: ходить, туда, нравиться, часто, год, друг, бывать, постоянно, каждый, рано\n"
     ]
    }
   ],
   "source": [
    "k = 20\n",
    "\n",
    "nmf = NMF( init=\"nndsvd\", n_components=k, random_state=42 ) \n",
    "W = nmf.fit_transform( A ) # тематическое представление тектов\n",
    "H = nmf.components_  # темы с вероятностями слов быть по ним\n",
    "\n",
    "get_all_descriptors(k, H, terms, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gs_vects = [vectorizer.transform([' '.join(m.lemmatize(x))]) for x in gs] # create \"docs\" from gold standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "аналогов нет [ 0 17 10 13 14]\n",
      "подошва [15  5  0  7  8]\n",
      "вежливый [11  9  2 12 15]\n",
      "великолепный [10 11  3  6  8]\n",
      "вкусный [11 16 14  7  9]\n",
      "внимательный [11  9  3 10 12]\n",
      "большой выбор [15  3  7  0  9]\n",
      "вау [17  0 18  1 19]\n",
      "неплохой [10  7 15 14 13]\n",
      "идеальный [ 0 11 17 10 15]\n",
      "неприятный [ 5 13  4  6 10]\n",
      "понравилось [ 2 19 18  1  3]\n",
      "рекомендуем [ 8 17 15 11  6]\n",
      "на ура [ 3 18 12 17  7]\n",
      "советуем [ 8 19 18 10  9]\n",
      "отвратительный [ 5 16 10 13 18]\n",
      "отличный [ 8 19 18  1  2]\n",
      "положительный [13 11  3 10  6]\n",
      "отрицательный [ 4  6  1 15  5]\n",
      "приятный [11 19  8  1  2]\n",
      "напоминать о себе [ 0  5  4  1 13]\n",
      "спасибо [ 3 11 18 19  8]\n",
      "радовать глаз [ 4 19 15 11  9]\n",
      "на совесть [ 4  3  0 12  8]\n",
      "молодцы [18  3  8  9  2]\n",
      "придти еще раз [ 2 11 18 12  5]\n",
      "орать [ 4 14 11  5 12]\n",
      "улыбаться [ 4  5 11  0  9]\n",
      "приветливый [11 13  9 19 12]\n",
      "отличный [ 8 19 18  1  2]\n",
      "замечательный [11 10 18  3  8]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[11, 8, 18, 3, 10, 9, 19, 0, 5, 15]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics = []\n",
    "for i,v in enumerate(gs_vects):\n",
    "    W = nmf.transform(v)\n",
    "    if sum(W[0]):\n",
    "        print(gs[i],np.argsort(W[0])[::-1][:5])\n",
    "        topics.append(np.argsort(W[0])[::-1][:5])\n",
    "sent_topics = [x[0] for x in Counter([y for x in topics for y in x]).most_common(10)]\n",
    "sent_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_words = sorted(list(all_words))\n",
    "all_words_vects = [vectorizer.transform([x]) for x in all_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_words = []\n",
    "waste = []\n",
    "for i,v in enumerate(all_words_vects):\n",
    "    W = nmf.transform(v)\n",
    "    if sum(W[0]):\n",
    "        ts = np.argsort(W[0])[::-1][:6]\n",
    "        if sum([x in sent_topics for x in ts]) > 3:\n",
    "            new_words.append(all_words[i])\n",
    "        else:\n",
    "            waste.append(all_words[i])\n",
    "    else:\n",
    "        waste.append(all_words[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brand_new_words = [x for x in new_words if x not in gs]\n",
    "len(brand_new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('sentiment_words.txt','w',encoding='utf-8-sig') as f:\n",
    "    f.write('\\n'.join(brand_new_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 46 79 0.4177215189873418\n"
     ]
    }
   ],
   "source": [
    "with open('rusentilex_2017.txt','r',encoding='utf-8') as f:\n",
    "    senti_words = {x.split(',')[0] for x in f.readlines()}\n",
    "\n",
    "in_dict = sum([x in senti_words for x in brand_new_words])\n",
    "total = len(brand_new_words)\n",
    "print(in_dict,total-in_dict,total,in_dict/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "безобразный\n",
      "безупречный\n",
      "бесподобный\n",
      "восхитительный\n",
      "грамотный\n",
      "доброжелательный\n",
      "добротный\n",
      "заботливый\n",
      "изумительный\n",
      "интересный\n",
      "любезный\n",
      "милый\n",
      "навязчивый\n",
      "объедение\n",
      "отвратный\n",
      "отзывчивый\n",
      "отменный\n",
      "потертость\n",
      "потрясать\n",
      "потрясающий\n",
      "превосходный\n",
      "предупредительный\n",
      "прекрасный\n",
      "пресный\n",
      "приемлемый\n",
      "профессиональный\n",
      "симпатичный\n",
      "смеяться\n",
      "ужасный\n",
      "улыбчивый\n",
      "уютный\n",
      "чудесный\n",
      "шикарный\n"
     ]
    }
   ],
   "source": [
    "for x in brand_new_words:\n",
    "    if x in senti_words:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out\n",
      "андрей\n",
      "барбареско\n",
      "благодарить\n",
      "великолепно\n",
      "вкусно\n",
      "гардеробщик\n",
      "громкость\n",
      "девушка\n",
      "жеваться\n",
      "жир\n",
      "завуалировать\n",
      "зажигательный\n",
      "зажигать\n",
      "замечательно\n",
      "картошка\n",
      "маринованный\n",
      "молодец\n",
      "негромкий\n",
      "ненавязчивый\n",
      "обалденный\n",
      "обслуживающий\n",
      "общаться\n",
      "ольга\n",
      "отблагодарить\n",
      "отвратительно\n",
      "перекрикивать\n",
      "поздороваться\n",
      "порадовать\n",
      "приветливо\n",
      "разговаривать\n",
      "раздевать\n",
      "разочаровывать\n",
      "ребята\n",
      "рекомендовать\n",
      "слушать\n",
      "смородиновый\n",
      "собеседник\n",
      "советовать\n",
      "удручающий\n",
      "улыбка\n",
      "умничек\n",
      "услужливый\n",
      "учтивый\n",
      "шутить\n",
      "этнический\n"
     ]
    }
   ],
   "source": [
    "for x in brand_new_words:\n",
    "    if x not in senti_words:\n",
    "        print(x)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
